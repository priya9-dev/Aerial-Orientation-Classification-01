{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec628d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    \")\\n\",\n",
    "        \"\\n\",\n",
    "        \"model.summary()\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Callbacks and training\\n\",\n",
    "        \"os.makedirs(os.path.join('..','models'), exist_ok=True)\\n\",\n",
    "        \"checkpoint_path = os.path.join('..','models', f'{model_choice}_best.h5')\\n\",\n",
    "        \"\\n\",\n",
    "        \"callbacks = [\\n\",\n",
    "        \"    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1),\\n\",\n",
    "        \"    tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\\n\",\n",
    "        \"    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1)\\n\",\n",
    "        \"]\\n\",\n",
    "        \"\\n\",\n",
    "        \"epochs = 10\\n\",\n",
    "        \"start_time = time.time()\\n\",\n",
    "        \"history = model.fit(\\n\",\n",
    "        \"    train_ds,\\n\",\n",
    "        \"    validation_data=valid_ds,\\n\",\n",
    "        \"    epochs=epochs,\\n\",\n",
    "        \"    callbacks=callbacks\\n\",\n",
    "        \")\\n\",\n",
    "        \"print(f'Training time: {time.time() - start_time:.1f}s')\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Save final model and plot training curves\\n\",\n",
    "        \"final_path = os.path.join('..','models', f'{model_choice}_final.h5')\\n\",\n",
    "        \"model.save(final_path)\\n\",\n",
    "        \"print('Saved model to', final_path)\\n\",\n",
    "        \"\\n\",\n",
    "        \"def plot_history(history, out_path=None):\\n\",\n",
    "        \"    h = history.history\\n\",\n",
    "        \"    plt.figure(figsize=(12,4))\\n\",\n",
    "        \"    plt.subplot(1,2,1)\\n\",\n",
    "        \"    plt.plot(h.get('accuracy', []), label='train_acc')\\n\",\n",
    "        \"    plt.plot(h.get('val_accuracy', []), label='val_acc')\\n\",\n",
    "        \"    plt.title('Accuracy')\\n\",\n",
    "        \"    plt.legend()\\n\",\n",
    "        \"    plt.subplot(1,2,2)\\n\",\n",
    "        \"    plt.plot(h.get('loss', []), label='train_loss')\\n\",\n",
    "        \"    plt.plot(h.get('val_loss', []), label='val_loss')\\n\",\n",
    "        \"    plt.title('Loss')\\n\",\n",
    "        \"    plt.legend()\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    if out_path:\\n\",\n",
    "        \"        plt.savefig(out_path)\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"plot_out = os.path.join('..','models', f'{model_choice}_training.png')\\n\",\n",
    "        \"plot_history(history, out_path=plot_out)\\n\",\n",
    "        \"print('Saved training plot to', plot_out)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"Notes:\\n\",\n",
    "        \"- If your preprocessing.create_data_generators returns class names, the notebook will print them.\\n\",\n",
    "        \"- Run this notebook in VS Code (Select Python kernel) or Jupyter. Paths assume notebook lives in notebooks/.\\n\",\n",
    "        \"- Adjust model_choice, batch size and epochs as needed.\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
